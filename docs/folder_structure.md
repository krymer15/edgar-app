# Folder Structure

```bash
edgar_app/
â”‚
â”œâ”€â”€ config/                   # Global configuration
â”‚   â””â”€â”€ app_config.yaml
â”‚   â””â”€â”€ config_loader.py
â”‚
â”œâ”€â”€ models/                   
|   â””â”€â”€ dataclasses/          # pure Python dataclasses for in-flight logic
â”‚       â”œâ”€â”€ raw_document.py
â”‚       â”œâ”€â”€ cleaned_document.py
|       â”œâ”€â”€ parsed_document.py
â”‚       â””â”€â”€ parsed_filing.py  # base class
â”‚
|   â””â”€â”€ orm_models/           # SQLAlchemy table mappings
|       â”œâ”€â”€ filing_metadata.py
|       â”œâ”€â”€ filing_document.py
|       â””â”€â”€ parsed_chunk_model.py
â”‚   â””â”€â”€ database.py           # session maker, engine
â”‚
|   â””â”€â”€ adapters/             # holds only conversion functions (dataclass â†” ORM)
|       â”œâ”€â”€ dataclass_to_orm.py
|       â””â”€â”€ orm_to_dataclass.py
â”‚
â”œâ”€â”€ utils/                    # Utility logic
â”‚   â”œâ”€â”€ path_manager.py       # File path resolver
â”‚   â”œâ”€â”€ ticker_cik_mapper.py
â”‚   â”œâ”€â”€ field_normalizer.py
â”‚   â””â”€â”€ report_logger.py
â”‚
â”œâ”€â”€ collectors/              # Fetch metadata (Phase 1)
â”‚   â””â”€â”€ filing_metadata_collector.py
â”‚
â”œâ”€â”€ downloaders/             # Download full raw files (Phase 2)
â”‚   â”œâ”€â”€ base_downloader.py
â”‚   â”œâ”€â”€ sgml_downloader.py
â”‚   â”œâ”€â”€ html_downloader.py
â”‚   â””â”€â”€ xml_downloader.py
â”‚
â”œâ”€â”€ cleaners/                # Strip raw files of style, prep for parsing
â”‚   â”œâ”€â”€ base_cleaner.py                   # Abstract base, shared utils
â”‚   â”‚
â”‚   â”œâ”€â”€ sgml/                             # SGML submissions  
â”‚   â”‚   â””â”€â”€ sgml_cleaner.py
â”‚   â”‚
â”‚   â”œâ”€â”€ html/                             # HTML cleanup  
â”‚   â”‚   â””â”€â”€ html_cleaner.py
â”‚   â”‚
â”‚   â””â”€â”€ xbrl/                             # XBRL cleanup  
â”‚       â””â”€â”€ xbrl_cleaner.py
â”‚
â”œâ”€â”€ parsers/                 # Parse raw/cleaned docs to structure
â”‚   â”œâ”€â”€ base_parser.py                    # Abstract base, shared utils
â”‚   â”œâ”€â”€ router.py                         # route_parser(form_type) â†’ appropriate parser
â”‚   â”‚
â”‚   â”œâ”€â”€ sgml/                             # SGML-specific parsing
â”‚   â”‚   â”œâ”€â”€ sgml_parser.py
â”‚   â”‚   â””â”€â”€ sgml_filing_parser_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ html/                             # HTML-based filings
â”‚   â”‚   â””â”€â”€ html_parser.py
â”‚   â”‚
â”‚   â”œâ”€â”€ xbrl/                             # XBRL-based filings
â”‚   â”‚   â””â”€â”€ xbrl_parser.py
â”‚   â”‚
â”‚   â”œâ”€â”€ form4/                            # Form 4 (XML)  
â”‚   â”‚   â””â”€â”€ form4_parser.py
â”‚   â”‚
â”‚   â””â”€â”€ eightk/                           # 8-K (often SGML + Exhibits)
â”‚      â””â”€â”€ eightk_parser.py
â”‚
â”œâ”€â”€ writers/                 # Write parsed data to DB
â”‚   â”œâ”€â”€ base_writer.py                    # Abstract base, shared DB logic
â”‚   â”‚
â”‚   â”œâ”€â”€ sgml/                             # Parsed SGML chunks â†’ DB  
â”‚   â”‚   â””â”€â”€ parsed_sgml_writer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ documents/                        # FilingDocument ORM writes  
â”‚   â”‚   â””â”€â”€ filing_documents_writer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ form4/                            # Form 4 â†’ specialized table (if any)
â”‚   â”‚   â””â”€â”€ form4_writer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ eightk/                           # 8-K â†’ exhibits table  
â”‚   â”‚   â””â”€â”€ eightk_writer.py
â”‚   â””â”€â”€ tenk/                             # 10-K â†’ XBRL financials table  
â”‚       â””â”€â”€ tenk_writer.py
â”‚
â”œâ”€â”€ embedders/               # Vectorization layer
â”‚   â””â”€â”€ openai_embedder.py
â”‚
â”œâ”€â”€ orchestrators/           # Pipeline control (by form or phase)
â”‚   â”œâ”€â”€ filing_metadata_orchestrator.py
â”‚   â”œâ”€â”€ filing_documents_orchestrator.py
â”‚   â””â”€â”€ form4_orchestrator.py
â”‚
â”œâ”€â”€ scripts/                 # CLI entrypoints and dev scripts
â”‚   â”œâ”€â”€ run_daily_metadata.py
â”‚   â”œâ”€â”€ run_form4_xml_ingest.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/                   # Unit and integration tests
â”‚   â”œâ”€â”€ test_path_manager.py
â”‚   â”œâ”€â”€ test_cli_ingestion.py
â”‚   â””â”€â”€ fixtures/
â”‚
â””â”€â”€ data/                    # Mounted SSD path (gitignored)
    â”œâ”€â”€ raw/
    â””â”€â”€ processed/
```
- Above we need an `adapters` folder for ORM to Dataclass, and Dataclass to ORM
Central Adapters module:
```bash
safeharbor_edgar_ai/
â””â”€â”€ models/
    â”œâ”€â”€ dataclass/
    â””â”€â”€ adapters/
        â””â”€â”€ dataclass_to_orm.py
```
In `dataclass_to_orm.py` youâ€™d collect all your conversion functions:

```python
def parsed_doc_to_orm(pd: ParsedDocument) -> FilingDocument: ...
def parsed_chunk_to_orm(pc: ParsedChunk) -> ParsedChunkModel: ...
def filing_to_orm(f: ParsedFiling) -> FilingMetadata: ...
```

Reverse Mapping: `orm_to_dataclass()`
Your orchestrators shouldnâ€™t import SQLAlchemy models directly. Instead, provide adapter functions:

```python
# models/adapters/orm_to_dataclass.py

def metadata_to_header(meta: FilingMetadata) -> FilingHeader:
    return FilingHeader(
        accession_number=meta.accession_number,
        form_type=meta.form_type,
        filing_date=meta.filing_date,
        report_date getattr(meta, "report_date", None),
    )

def document_model_to_raw(doc_model: FilingDocument) -> RawDocument:
    return RawDocument(
        accession_number=doc_model.accession_number,
        cik=doc_model.cik,
        form_type=doc_model.filing.form_type,
        filename=doc_model.filename,
        source_url=doc_model.source_url,
        doc_type=doc_model.source_type,
        source_type=doc_model.source_type,
        is_primary=doc_model.is_primary,
        is_exhibit=doc_model.is_exhibit,
        accessible=doc_model.accessible,
    )
```

--------
## Notes on Design
âœ… @dataclass: Ideal for in-memory transport, parsing logic, and LLM prompts.
âœ… ORM models: Only used in `writers/` and `collectors/` for DB read/write.
âœ… Path Manager: Central resolver so no hardcoded file logic elsewhere.
âœ… Separation of Phases: Phase 1 = metadata; Phase 2 = file download; Phase 3 = parsing; Phase 4 = embedding.

## Folder Structure with Specialized Subclasses:

```bash
models/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ filing_document.py       # Base FilingDocument, DownloadedDocument, etc.
â”‚   â”œâ”€â”€ parsed_filing.py         # Base ParsedFiling. Subclass `ParsedFiling` and group by form in folders
â”‚   â””â”€â”€ parsed_chunk.py
â”‚
â”œâ”€â”€ form4/
â”‚   â”œâ”€â”€ parsed_form4.py          # ParsedForm4 extends ParsedFiling
â”‚   â””â”€â”€ xml_models.py            # Optional: XML tag-specific dataclasses
â”‚
â”œâ”€â”€ form10k/
â”‚   â”œâ”€â”€ parsed_10k.py            # Parsed10K extends ParsedFiling
â”‚   â””â”€â”€ xbrl_models.py           # e.g., Revenue, NetIncome from us-gaap tags
â”‚
â””â”€â”€ __init__.py
```

### Example (Subclassing `ParsedFiling`)

```python
# models/base/parsed_filing.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class ParsedFiling:
    cik: str
    accession_number: str
    form_type: str
    parsed_at: Optional[str] = None  # ISO timestamp
```

```python
# models/form4/parsed_form4.py
from dataclasses import dataclass
from models.base.parsed_filing import ParsedFiling

@dataclass
class ParsedForm4(ParsedFiling):
    issuer_cik: str
    insider_name: str
    transaction_date: str
    shares_acquired: float
    shares_disposed: float
```
Then, conceivably, in a `parsers/form_router.py`:

```python
def route_parser(form_type: str):
    if form_type == "4":
        return Form4Parser()
    elif form_type == "10-K":
        return Xbrl10kParser()
    else:
        raise NotImplementedError(f"No parser available for {form_type}")
```


## Should You Use Pydantic to Convert to Internal Dataclasses?
Short answer: No, not unless you're building a public-facing API layer or need complex validation logic.

ğŸ” Why not Pydantic here:
- You already use SQLAlchemy ORM â€” introducing Pydantic for internal use adds overhead and redundancy.
- Pydantic adds runtime validation and serialization, which you donâ€™t typically need when passing already-known-good objects internally between modules like parsers, embedders, and writers.
- Speed: Native @dataclass is faster and simpler, especially for batch workloads like yours.

âœ… Recommended:
Use standard Python @dataclass for all internal data modeling. If you ever expose a FastAPI or Flask API later, you can layer Pydantic separately for validation at the boundary.

## Why a Factory Method Instead of `.from_orm()` Pydantic?
- A factory method is a custom class method (typically from_orm(), from_db_model(), or similar) that instantiates a dataclass using an ORM object.
- This gives you full control, keeps it lightweight, and doesnâ€™t require external libraries like Pydantic.
- We implement this through modules in `models/adapters/`.
